{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d845b8e8-da26-4b3f-9ff5-c3c87f3f0d8a",
   "metadata": {},
   "source": [
    "#### Building Baseline Models\n",
    "Baseline models serve as a reference point for evaluating the performance of more complex models. They provide a simple, interpretable way to measure improvements and assess whether an advanced model is actually performing better than a naive approach. We will start with Linear Regression, then progress to Random Forest and then use Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a888c1-c33b-47fe-aef3-c03a3f9f888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67392e3-f0d0-4cc4-9b84-9044c6d35d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/content/drive/MyDrive/SnowPackPredictionChallenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a21da-6b2e-4daa-b8d1-36a4e58d1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse swe_data\n",
    "df = pd.read_csv(root + '/feature_engineered_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadc169-2347-452c-b7cc-d25586b0db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variable\n",
    "features = [\"Latitude\", \"Longitude\", \"Elevation\", \"Southness\",\n",
    "    \"precip\", \"tmin\", \"tmax\", \"SPH\", \"SRAD\", \"Rmax\", \"Rmin\", \"windspeed\",\n",
    "    \"SWE_lag1\", \"SWE_lag3\", \"SWE_lag7\",\n",
    "    \"precip_lag1\", \"tmin_lag1\", \"tmax_lag1\", \"SPH_lag1\",\n",
    "    \"SRAD_lag1\", \"Rmax_lag1\", \"Rmin_lag1\", \"windspeed_lag1\",\n",
    "    \"SWE_roll3\", \"SWE_roll7\", \"precip_roll3\", \"tmin_roll3\"]\n",
    "target = \"SWE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e45a7-0e62-48f6-a748-b43fc7b6ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_val, y_val = val_df[features], val_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621b193-088f-4f93-ab33-24d5063a0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": HistGradientBoostingRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4950e-ed3d-40e8-bb07-be6d63905891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33a5a2-d2fc-4367-b346-e60e1bc65e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models with validated data\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_lr = model.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred_lr))\n",
    "r2 = r2_score(y_val, y_pred_lr)\n",
    "model_results = {\"RMSE\": rmse, \"R2\": r2}\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541e251-62f3-43dc-9040-84da94202277",
   "metadata": {},
   "source": [
    "#### Model Evaluation - Compute NSE, RMSE, RÂ² Score, and Relative Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423d3b5-4336-443c-8f23-98e085464c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Compute RÂ² Score\n",
    "r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# Compute Relative Bias (%)\n",
    "relative_bias = (np.sum(y_pred_lr - y_test) / np.sum(y_test)) * 100\n",
    "\n",
    "# Compute Actual Error (Prediction - Observed)\n",
    "actual_error = y_pred_lr - y_test\n",
    "\n",
    "# Compute NSE (Nash-Sutcliffe Efficiency)\n",
    "observed_mean = np.mean(y_test)\n",
    "nse = 1 - (np.sum((y_pred_lr - y_test) ** 2) / np.sum((y_test - observed_mean) ** 2))\n",
    "\n",
    "# Create a results DataFrame\n",
    "evaluation_results = pd.DataFrame({\n",
    "    \"Metric\": [\"Nash-Sutcliffe Efficiency (NSE)\", \"Root Mean Square Error (RMSE)\", \"RÂ² Score\", \"Relative Bias (%)\", 'Prediction Error'],\n",
    "    \"Value\": [nse, rmse, r2, relative_bias, actual_error]\n",
    "})\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nðŸ“Š Model Evaluation Metrics:\")\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184aa970-3cec-4d2b-87a0-643a92f627b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "        \"Date\": test_df[\"Date\"],\n",
    "        \"Latitude\": test_df[\"Latitude\"],\n",
    "        \"Longitude\": test_df[\"Longitude\"],\n",
    "        \"SWE_actual\": y_test,\n",
    "        \"SWE_predicted\": y_pred_lr\n",
    "    })\n",
    "predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "evaluation_results.append({\n",
    "        \"Model\": \"Linear Regression\",\n",
    "        \"RMSE\": rmse,\n",
    "        \"Actual Error\": actual_error,\n",
    "        \"RÂ² Score\": r2,\n",
    "        \"NSE\": nse,\n",
    "        \"Relative Bias (%)\": relative_bias\n",
    "    })\n",
    "evaluation_df.to_csv(\"evaluation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe589e85-38f7-4103-b3b8-bfd6f26950f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
